{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 关于Patch Merging问题的讨论\npatch merging操作的目的是将feature map进行下采样并且通道维度翻倍，我在重复代码的时候使用的是kernel size为2，步长为2的卷积实现此操作，而swin transformer中官方代码在patch merging过程中使用了一系列操作，将水平和竖直方向像素块间隔一个拼接再重新堆叠（实现了水平和竖直尺寸缩减为二分之一，通道数增加了四倍），然后再做个layer norm，之后通道维度做线性层降低一半的的维度。整个过程见下面两段代码演示，假设下面生成的是三通道4\\*4的feature map转变成的高2宽2通道为3\\*4的feature map","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nx1 = torch.ones(size=(4,4,3)).int()\nx1[1::2, 0::2, 0] = 255\nx1[0::2, 1::2, 1] = 255\nx1[1::2, 1::2, 2] = 255\nax = plt.subplot(1, 2, 1)\nax.imshow(x1)\nax.set_title(\"before\")\nax.set_xticks([])\nax.set_yticks([])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T14:15:15.640047Z","iopub.execute_input":"2022-03-09T14:15:15.640377Z","iopub.status.idle":"2022-03-09T14:15:17.536228Z","shell.execute_reply.started":"2022-03-09T14:15:15.640336Z","shell.execute_reply":"2022-03-09T14:15:17.535361Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"x2 = x1.view(2,2,2,2,3).transpose(1,2).reshape(2,2,12)\nfor i in range(4):\n    ax = plt.subplot(1, 4, i+1)\n    ax.imshow(x2[:,:,3*i:3*(i+1)])\n    ax.set_title(f\"ch{i}\")\n    ax.set_xticks([])\n    ax.set_yticks([])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T14:15:21.350015Z","iopub.execute_input":"2022-03-09T14:15:21.350345Z","iopub.status.idle":"2022-03-09T14:15:21.559423Z","shell.execute_reply.started":"2022-03-09T14:15:21.350297Z","shell.execute_reply":"2022-03-09T14:15:21.558391Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"仔细思考后发现其实做卷积操作和拼接后再做线性映射（或者1*1卷积）没什么不同，FLOPs经过计算也是相同的，无非初始化的方式不同有一定程度的影响，不明白为何采用这么麻烦的拼接再做线性映射，后来明白这种对像素的间隔取样是种常规操作虽然FLOPs相同但计算起来这种线性映射更快，根据朱毅老师在某评论区提出的观点看应该也是提高效率的一种技巧，并指出使用pixel shuffle对效率提升可能更有效果，之前没听说过pixel shuffle，但根据名字猜想应该跟shuffleNet中的channel shuffle是差不多的东西，实现上来说就是对应的维度经过转置再重新reshape成符合的维度，直接省略掉了索引加拼接的步骤，简单的测试如下。","metadata":{}},{"cell_type":"markdown","source":"- 首先验证一下两种方法得到的结果是相同的","metadata":{}},{"cell_type":"code","source":"def shuffle_pix(x):\n    H, W, C = x.shape\n    return x.view(H//2,2,W//2,2,C).permute(0,2,1,3,4).reshape(H//2,W//2,4*C)\n\ndef split_pix(x):\n    H, W, C = x.shape\n    x0 = x[0::2, 0::2, :]  # B H/2 W/2 C\n    x1 = x[1::2, 0::2, :]  # B H/2 W/2 C\n    x2 = x[0::2, 1::2, :]  # B H/2 W/2 C\n    x3 = x[1::2, 1::2, :]  # B H/2 W/2 C\n    x = torch.cat([x0, x2, x1, x3], -1)  # B H/2 W/2 4*C\n    return x.view(H//2, W//2, -1)  # B H/2*W/2 4*C\n\nx = torch.randn(56,56,96)\ny1 = shuffle_pix(x)\ny2 = split_pix(x)\n(y1==y2).all()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:36:27.267267Z","iopub.execute_input":"2022-03-09T10:36:27.267950Z","iopub.status.idle":"2022-03-09T10:36:27.292583Z","shell.execute_reply.started":"2022-03-09T10:36:27.267911Z","shell.execute_reply":"2022-03-09T10:36:27.287477Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"- 根据swin transformer官方代码修改，将pixel shuffle操作做简单的不严谨的对比。（之前在gpu上官方patch merging比卷积快五倍左右，shuffle操作只比官方patch merging操作快了一点点）。","metadata":{}},{"cell_type":"code","source":"class PatchMerging(nn.Module):\n    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm, pix_shuffle=True):\n        super().__init__()\n        self.input_resolution = input_resolution\n        self.dim = dim\n        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n        self.norm = norm_layer(4 * dim)\n        self.pix_shuffle= pix_shuffle\n\n    def forward(self, x):\n        \"\"\"\n        x: B, H*W, C\n        \"\"\"\n        H, W = self.input_resolution\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n        \n        x = x.view(B, H, W, C)\n        \n        if self.pix_shuffle:\n            x = x.view(B,H//2,2,W//2,2,C).permute(0,1,3,2,4,5).reshape(B,H//2,W//2,4*C)\n        else:\n            x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n            x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n            x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n            x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n            x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n            x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n\n        x = self.norm(x)\n        x = self.reduction(x)\n\n        return x\n    \nimport time\nx = torch.randn(128,56*56,96)\npatch_merge = PatchMerging((56,56),96,pix_shuffle=False)\nshuffle_pix = PatchMerging((56,56),96)\nt1 = time.time()\npatch_merge(x)\nt_end = time.time()-t1\nprint(f\"patch merging用时{t_end}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:35:29.068420Z","iopub.execute_input":"2022-03-09T10:35:29.069417Z","iopub.status.idle":"2022-03-09T10:35:29.819878Z","shell.execute_reply.started":"2022-03-09T10:35:29.069356Z","shell.execute_reply":"2022-03-09T10:35:29.818868Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"t1 = time.time()\nshuffle_pix(x)\nt_end = time.time()-t1\nprint(f\"pix shuffle用时{t_end}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:35:31.249530Z","iopub.execute_input":"2022-03-09T10:35:31.250333Z","iopub.status.idle":"2022-03-09T10:35:31.527243Z","shell.execute_reply.started":"2022-03-09T10:35:31.250296Z","shell.execute_reply":"2022-03-09T10:35:31.526298Z"},"trusted":true},"execution_count":6,"outputs":[]}]}
